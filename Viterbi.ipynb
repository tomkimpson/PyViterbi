{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the Viterbi algorithm\n",
    "\n",
    "\n",
    "The Viterbi algorithm is a well-known optimization algorithm for hidden Markov models.\n",
    "\n",
    "\n",
    "This notebook demonstrates a basic implementation.\n",
    "\n",
    "----\n",
    "\n",
    "## Intro\n",
    "\n",
    "The Viterbi algorithm allows you to find the most probable sequence of hidden states, given some observations i.e.\n",
    "\n",
    "$$ Q^*(O) = \\text{argmax} P(Q|O)$$\n",
    "\n",
    "for path Q, optimal path $Q^*$ and observations $O$\n",
    "\n",
    "See e.g. [Suvorova et al 2016](https://arxiv.org/pdf/1606.02412.pdf) for an example astrophysical implementation.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def viterbi(y,transition_matrix,emission_matrix,initial_state):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    A function to implement the Viterbi algorithm for HMM optimization\n",
    "\n",
    "    Inputs:\n",
    "        y                    :: Sequence of observations. Vector(T), Int dtype\n",
    "        transition_matrix    :: Matrix of transition probabilities. Array (K,K)\n",
    "        emission_matrix      :: Matrix of emission probabilities. Array (K,N) for N unique observation states\n",
    "        initial_states       :: Initial probabilities system occupies each hidden state. Vector(K)\n",
    "\n",
    "    Outputs:\n",
    "        path                 :: Estimated hidden state path \n",
    "        probability          :: Probability of the path\n",
    "\n",
    "    Acknowledgements:  https://stackoverflow.com/a/49351064/1887919\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Dimensions\n",
    "    K = transition_matrix.shape[0] # Number of unique hidden states\n",
    "    T = len(y)                     # Number of observations\n",
    "\n",
    "\n",
    "    # Initialise two empty tables \n",
    "    T1 = np.zeros((K, T), 'd') #Tracking table T1, with double precison type. This is equivalent to \\delta, Eq 11 from Suvorova.\n",
    "    T2 = np.zeros((K, T), 'B') #Tracking table T2, with unsigned byte type. This is equivalent to \\Phi, Eq 11 from Suvorova.\n",
    "\n",
    "\n",
    "    #1. Initialization\n",
    "\n",
    "    T1[:,0] = initial_state * emission_matrix[:, y[0]]\n",
    "    T2[:, 0] = 0\n",
    "\n",
    "\n",
    "    #2. Iterate\n",
    "    # Iterate through the observations, updating the tracking tables. \n",
    "    # Index from 1 since the 0th element has already been set in the initialisation\n",
    "    for i in range(1,T):\n",
    "        T1[:,i] = np.max(T1[:, i - 1] * transition_matrix.T * emission_matrix[np.newaxis, :, y[i]].T,1) # This is Eq. 15 fro Suvorova\n",
    "        T2[:,i] = np.argmax(T1[:,i-1]*transition_matrix.T,1)                                            #...and Eq. 16 \n",
    "\n",
    "\n",
    "    #3. Infer the most probable hidden state path\n",
    "    path = np.zeros(T, 'B')\n",
    "    path[-1] = np.argmax(T1[:,T-1]) # Index of best final state\n",
    "\n",
    "\n",
    "    #Backtrack\n",
    "    for i in reversed(range(1,T)):\n",
    "        path[i-1] = T2[path[i],i]\n",
    "\n",
    "    probability = max(T1[:,T-1]) \n",
    "    return path, probability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check this is working ok by comparing it to the [worked example on Wikipedia](https://en.wikipedia.org/wiki/Viterbi_algorithm#Example).\n",
    "\n",
    "In this case there are two hidden states _\"Healthy\"_ and _\"Fever\"_ and 3 observation states _\"normal\"_, _\"cold\"_ and _\"dizzy\"_.\n",
    "\n",
    "The sequence of observations is simply `(normal,cold,dizzy)`.\n",
    "\n",
    "Lets solve this using the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [\"normal\", \"cold\", \"dizzy\"] # observations\n",
    "y = [0,1,2]                       # integer dtype corresponding to observation states\n",
    "transition_matrix = np.array([[0.7, 0.3], [0.4, 0.6]])       # probabilities of transitions from one hidden state to another. From Wiipedia example \n",
    "emission_matrix = np.array([[0.5, 0.4,0.1], [0.1,0.3, 0.6]]) # probabilities of observations GIVEN a hidden state. From Wiipedia example \n",
    "initial_state = [0.6,0.4] #initial state probabilities\n",
    "\n",
    "path,probability = viterbi(y,transition_matrix,emission_matrix,initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to _\"Healthy\"_,_\"Healthy\"_, _\"Fever\"_ which agrees with the Wiki example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which also agrees âœ…"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('workhorse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "760d1385bb695b8ee3e655c95a5dbe9017a7f70fce273386d3e181e28289afb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
